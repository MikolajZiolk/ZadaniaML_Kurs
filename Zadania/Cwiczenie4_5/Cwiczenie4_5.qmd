---
title: "Zadanie4_5"
date: today
author: "Mikołaj Ziółkowski"
editor: visual
format: 
  html:
    toc: true
    toc-depth: 3
    toc-location: right
    toc-title: Spis Treści
    number-sections: true
    number-depth: 3
    embed-resources: true
    html-math-method: katex
    code-tools: true
    code-block-bg: true
    code-fold: true
    code-summary: "Show and hide code"
    link-external-icon: true
    link-external-newwindow: true
    smooth-scroll: true
    self-contained: true
    citation: true
    theme: 
        dark: solar
        light: flatly
    fontsize: 1.0em
    linestretch: 1.3
    fig-align: center
execute: 
  eval: true
  echo: true
  error: false
  warning: false
  output: true
---

# Zadnie 4_5

## Biblioteki
```{r}
library(tidymodels) 
library(skimr) 
library(GGally)
library(ggpubr)
library(dplyr)
library(openair) 
library(DT)
library(ranger)
library(vip)
tidymodels_prefer()
```

## Zadanie 4
```{r}
args(decision_tree)
```
## Zadanie 5

*Polecenie*
Zoptymalizuj hiper-parametry w modelu lasu losowego utworzonego w ćwiczeniu nr 3. Dostosuj ilość współczynników w siatce hiper-parametrów.

### Przygotowanie danych

```{r}
air <- mydata |> selectByDate(year = 2002) |> na.omit()
air |> skim()
```

```{r}
air |>    
  ggplot(aes(date, o3)) +     
  geom_line() +     
  theme_bw()  
```

### Tworzenie zmiennej jakościowej ozone

```{r}
air <-
  air |>
  mutate(ozone = cut(
    o3,
    breaks = c(-0.1, 10, 53),
    labels = c("Niskie", "Wysokie")
  ))

air |> count(ozone)
```

### Podział na zbiór testowy i treningowy

```{r}
set.seed(222)
data_split <-initial_split(air, prop = 0.75, strata = ozone)
train_data <- training(data_split)
test_data <- testing(data_split)
```

### Resampling CV_folds, r5, bootstrap

```{r}
set.seed(345)
cv_folds <- vfold_cv(data = train_data)
cv_folds_r5 <- vfold_cv(data=train_data, v=10, repeats = 5)
bootstrap_folds <- bootstraps(data=train_data, times=5)
```

### Tworzenie receptury

```{r}
oz_rec <- 
  recipe(ozone ~ ., data = train_data) |>
  update_role(o3, wd, date, pm10, pm25, so2, co, no2, new_role = "ID") |> 
  step_BoxCox(ws, nox, no2) |>
  step_date(date, features = c("month")) |> #kolumna jakościowa
  step_time(date, features = c("hour")) |> 
  step_mutate(date_hour = as.factor(date_hour)) |>  
  step_dummy(all_nominal_predictors()) |>  # Tworzenie zmiennych fikcyjnych
  step_zv()

oz_rec |> summary()

oz_rec |> 
  prep()
```
### Zdefiniowanie hyper parametrów do tune

Tworze specyfikacje, która określa, które parametry lasu losowego dostroić

```{r}
tune_spec <-
  rand_forest(mtry = tune(),
              min_n = tune(),
              trees = 1000) |>
  set_engine(engine = "ranger",
             num.threads=parallel::detectCores() - 1,
             importance = "impurity") |>
  set_mode(mode = "classification")

tune_spec
```
### Siatka

```{r}
reg_grid  <- grid_regular(
  mtry(range=c(1,10)),
  min_n(),
  levels=5)

reg_grid
```
### Podgląd parametrów 

```{r}
reg_grid |> 
  count(mtry)

reg_grid |> 
  count(min_n)
```
### Stworzenie workflow

```{r}
tune_work  <- 
  workflow() |> 
  add_model(tune_spec) |> 
  add_recipe(oz_rec)
```

### Statystyki oceny dokładnosci modelu 

```{r}
set.seed(345)
ex_metrics  <- 
  yardstick::metric_set(
    accuracy,
    mcc,
    npv,
    roc_auc
  )

rf_tune_fit <- 
  tune_work |> 
  tune_grid(resamples = cv_folds, 
            grid = reg_grid, 
            control = control_grid(save_pred = T),
            metrics = ex_metrics)

```

### Metryki tune i resample

```{r}

rf_tune_fit |> collect_metrics()

rf_tune_fit |> 
  collect_metrics() |> 
  mutate(mtry = factor(mtry)) |> 
  ggplot(aes(min_n, mean, color = mtry)) +
  geom_line(linewidth = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)

```

### Najlepszy model

Wyświetlenie najlepszych wyników i stworzenie najlepiej pasującego modelu do tune.

```{r}
rf_tune_fit |> show_best(metric="accuracy")
```

```{r}
best_mod <- 
  rf_tune_fit |> 
  select_best(metric="accuracy")

final_mod <-  
  tune_work |> 
  finalize_workflow(best_mod)
```

### Dopasowanie ostatecznego modelu do danych uczących

```{r}
final_fit <- 
  final_mod |> 
  last_fit(split = data_split)

final_fit |> 
  collect_metrics()

final_fit |> 
  collect_predictions() |> 
  roc_curve(truth = ozone, .pred_Niskie) |> 
  autoplot()
```

### Istotność parametrów w modelu

```{r}
final_fit |> extract_workflow()
```

```{r}
final_fit |> 
  extract_workflow() |> 
  extract_fit_engine() |> 
  vip()
```

### Model bez resample i tuningu

```{r}
#modele bez resample i tunning
lr_mod <-
  logistic_reg() |> 
  set_engine("glm")

#workflow
oz_work <- 
  workflow() |> 
  add_model(lr_mod) |> 
  add_recipe(oz_rec)

oz_fit <-
  oz_work |> 
  fit(data =train_data)
```

### Przewidywanie bez resample i tuningu

```{r}
predict(oz_fit, test_data, type="prob")
```

### Połączenie oz_fit z test_data

```{r}
pred_test <- 
  augment(oz_fit, test_data) |>
  select(-ws,
         -wd,
         -nox,
         -o3,
         -nox,
         -no2,
         -pm10,
         -pm25,
         -so2,
         -co,
         -date)
pred_test
```

### Model RF bez tuningu

```{r}
#parsnip - model, rf, bez tuningu
rf_mod <-
  rand_forest() |> 
  set_engine(engine = "ranger",
            num.threads=parallel::detectCores() - 1) |> 
  set_mode("classification")

rf_workflow <-
  workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(oz_rec)
```

### Dopasowanie resample

```{r}
#tune rf
set.seed(456)
rf_fit_rs <-
  rf_workflow |> 
  fit_resamples(cv_folds)

rf_fit_bootstrap <- 
  rf_workflow |>
  fit_resamples(bootstrap_folds) 

rf_fit_r5 <- 
  rf_workflow |> 
  fit_resamples(cv_folds_r5)

```

### Metryki bez resample
```{r}
metrics_no_resample <- bind_rows(
  pred_test |>
    roc_auc(truth = ozone, .pred_Niskie),
  
  pred_test |>
    accuracy(truth = ozone, .pred_class)
) |>
  mutate(.approach = "no resampling")

```

### Metryki z resample

```{r}

metrics_rf_vcv_r5 <- rf_fit_r5|> 
  collect_metrics() |> 
  filter(.metric == "accuracy" | .metric == "roc_auc") |>
  mutate(.approach = "rf_cv_r5")
```

### Metryki z Tune

```{r}
metricsTune <- final_fit |> 
  collect_metrics() |> 
  filter(.metric == "accuracy" | .metric == "roc_auc") |>
  mutate(.approach = "tune")
```

### Porównanie metryk

```{r}
all_metrics <- bind_rows(
  metrics_no_resample,
  metrics_rf_vcv_r5,
  metricsTune
)

knitr::kable(all_metrics, caption = "Porównanie Metryk", align = "c")
```
