---
title: "Zadanie6"
date: today
author: "Mikołaj Ziółkowski"
editor: visual
format: 
  html:
    toc: true
    toc-depth: 3
    toc-location: right
    toc-title: Spis Treści
    number-sections: true
    number-depth: 3
    embed-resources: true
    html-math-method: katex
    code-tools: true
    code-block-bg: true
    code-fold: true
    code-summary: "Show and hide code"
    link-external-icon: true
    link-external-newwindow: true
    smooth-scroll: true
    self-contained: true
    citation: true
    theme: 
        dark: solar
        light: flatly
    fontsize: 1.0em
    linestretch: 1.3
    fig-align: center
execute: 
  eval: true
  echo: true
  error: false
  warning: false
  output: true
---

# Zadanie 6

## Przygotowanie danych i ich podział

### Polecenie

Na podstawie danych mydata (1 rok) zaproponuj model prognozowania poziomów stężeń O3 (modele regresji). Zastosuj trzy metody:

- regresja liniowa prosta (glmnet),

- drzewa decyzyjne (rpart)

- las losowy (ranger).

Najważniejsze punkty:

- przekształć kierunek wiatru na zmienną kategoryczną, definiując 16 kierunków wiatru.

- utwórz zestaw walidacyjny bez resamplingu,

- utwórz receptury dla każdego modelu - sprawdź wymagania modeli,

- przeprowadź optymalizację hiper-parametrów,

- zbuduj ostateczny modele,

- Sprawdź który model był najlepszy,

- Najlepszą graficzną metodą porównania wyników oceny dokładności na zbiorze testowym jest wykres rozrzutu z linią modelu idealnego.

### Potrzebne pakiety

```{r}
library(tidymodels) 
library(skimr) 
library(GGally)
library(ggpubr)
library(dplyr)
library(openair) 
library(DT)
library(ranger)
library(glmnet)
library(readr)
library(ggthemes)
library(purrr)
library(vip)
tidymodels_prefer()
```

### Przygotowanie danych

```{r}
air <- mydata |> 
  selectByDate(year = 2002) |> 
  na.omit()

air |> glimpse()
```
### Korelacja

```{r}
air[sample(1:nrow(air), size = 300, replace = F),] |> 
  ggpairs()
```
Występuje istotna korlacja pomiędzy O3 a pozostałymi zmiennymi.

### Przekształcenie kierunków wiatru na zmienną kategoryczną, definiując 16 kierunków wiatru.

```{r}
# Tworzenie wektora z nazwami kierunków
wind_directions <- c("N", "NNE", "NE", "ENE", "E", "ESE", "SE", "SSE", 
                     "S", "SSW", "SW", "WSW", "W", "WNW", "NW", "NNW")


# Przekształcenie `wd` na kierunki wiatru
air <- air |>
  mutate(
    wind_category = cut(
      wd,
      breaks = seq(0, 360, length.out = 17), # 17 punktów dzieli na 16 przedziałów
      labels = wind_directions,
      include.lowest = TRUE
    )
  )

air |> count(wind_category)
```

### Podział danych na zbiór treningowy i zbiór testowy

```{r}
set.seed(222)
data_split <-initial_split(air, prop = 0.75, strata = o3)
train_data <- training(data_split)
test_data <- testing(data_split)
```

### Zbiór walidacyjny

```{r}
val_set <-
  validation_split(data = train_data,
                   prop = 3 / 4,
                   strata = o3) 

```

## Regresja liniowa prosta

### Model regresji liniowej
```{r}
lin_mod <-
  linear_reg(penalty = tune(),
               mixture = tune()) |>
  #mixture = 1 oznacza, że model glmnet potencjalnie usunie nieistotne predyktory i wybierze prostszy model.
  set_engine(engine = "glmnet",
             num.threads = parallel::detectCores() - 1) |>
  set_mode("regression")
```

### Receptura lr
```{r}
lin_recipe <-    
  recipe(o3 ~ ., data = train_data) |>  
  update_role(date, pm10, pm25, new_role = "ID") |> 
  step_date(date, features = c("month")) |> #kolumna jakościowa
  step_time(date, features = c("hour")) |>    
  step_rm(date) |>    
  step_dummy(all_nominal_predictors()) |>    
  step_zv(all_predictors())


lin_recipe |> 
  prep() |>
  bake(train_data) |> 
  glimpse()
```
### Workflow lr

```{r}
lin_workflow <-    
  workflow() |>    
  add_model(lin_mod) |>    
  add_recipe(lin_recipe)

```

### Siatka optymalizacji hipermaparametrów lr
```{r}
lin_grid <- grid_regular(penalty(),mixture(), levels = 5) 
lin_grid
```

### Tune dla modelu

Ucznie i optymalizacja modelu:

```{r}
lin_res <-
  lin_workflow |>
  tune_grid(
    resamples = val_set,
    grid = lin_grid,
    control = control_grid(save_pred = TRUE),
    metrics = metric_set(mae)
  )
```
### Wykaz kandydatów na najlepszy model
```{r}
top_lin_models <- 
  lin_res |> 
  show_best(metric="mae", n = Inf) |> 
  arrange(penalty) |> 
  mutate(mean = mean |> round(x = _, digits = 3))

top_lin_models |> gt::gt()
```

### Wybór najlepszego modelu
```{r}
lin_best <-
  lin_res |>
  select_best(metric="mae")

lin_best
```

### Model ostateczny i jego dopasowanie
```{r}
lin_best_mod <-
  lin_workflow |>
  finalize_workflow(lin_best)

lin_fit <-
  lin_best_mod |>
  last_fit(split = data_split)
```

## Las losowy

### Model random forest
```{r}
rf_mod <-
  rand_forest(mtry = tune(),
              min_n = tune(),
              trees = tune()) |>
  set_engine(engine = "ranger",
             num.threads = parallel::detectCores() - 1,
             importance = "impurity") |>
  set_mode(mode = "regression")
```

### Receptura rf
```{r}
rf_recipe <- 
  recipe(o3 ~ ., data = train_data) |> 
  update_role(date, pm10, pm25, new_role = "ID") |>
  step_date(date, features = c("month")) |> #kolumna jakościowa
  step_time(date, features = c("hour")) |> 
  step_rm(date) |> 
  step_zv(all_predictors()) 

rf_recipe |>
  prep() |>
  bake(train_data) |>
  glimpse()
```

### Workflow rf

```{r}
rf_workflow <- 
  workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(rf_recipe)
```

### Siatka regularna rf

```{r}
rf_grid <-
  grid_regular(
    mtry(range=c(1, 8)),
    trees(),
    min_n(),
    levels = 5
  )

rf_grid
```

### Tune dla modelu rf
```{r}
rf_res <- 
  rf_workflow |> 
  tune_grid(resamples = val_set, 
            grid = rf_grid, 
            control = control_grid(save_pred = T),
            metrics = metric_set(mae))
rf_res
```

### Wykaz kandydatów na najlepszy model
```{r}
rf_top_models <-
  rf_res |>
  show_best(metric="mae", n = Inf) |>
  arrange(trees) |>
  mutate(mean = mean |> round(x = _, digits = 3))

rf_top_models |> gt::gt()
```

### Wybór najlepszego modelu
```{r}
rf_res |> show_best(n = 5, metric="mae") #5 najlepszych wyników

rf_best <-
  rf_res |>
  select_best(metric="mae")

rf_best
```

### Model ostateczny i jego dopasowanie
```{r}
#model ostateczny
rf_best_mod <-
  rf_workflow |>
  finalize_workflow(rf_best)

rf_fit <-
  rf_best_mod |>
  last_fit(split = data_split)
```


## Drzewo decyzyjne

### Model decision tree
```{r}
dec_mod <- 
  decision_tree(
    cost_complexity = tune(), 
    tree_depth = tune(),
    min_n = tune()) |> 
  set_engine("rpart") |> 
  set_mode("regression")
dec_mod
```
### Recpetura dec
```{r}
dec_rec <-
  recipe(o3 ~ ., data = train_data) |>
  update_role(date, pm10, pm25, new_role = "ID") |>
  step_date(date, features = c("month")) |> 
  step_time(date, features = c("hour")) |>
  step_rm(date) |> 
  step_zv(all_predictors()) 

dec_rec |>
  prep() |>
  bake(train_data) |>
  glimpse()
```

### Workflow dc

```{r}
dec_workflow <- 
  workflow() |> 
  add_model(dec_mod) |> 
  add_recipe(dec_rec)
```


### Siatka regularna

```{r}
dec_grid <- grid_regular(cost_complexity(), 
                       tree_depth(), 
                       min_n(),
                       levels = 5)
dec_grid

```

### Optymalizacja TUNE
```{r}
dec_fit_tree <-
  dec_workflow |>
  tune_grid(
    resamples = val_set,
    grid = dec_grid,
    control = control_grid(save_pred = T),
    metrics = metric_set(mae)
  )
```


### Wykaz kandydatów na najlepszy model
```{r}
dec_top_models <-
  dec_fit_tree |>
  show_best(metric="mae", n = Inf) |>
  arrange(tree_depth) |>
  mutate(mean = mean |> round(x = _, digits = 3))

dec_top_models |> gt::gt()
```

### Wybór najlepszego modelu
```{r}
dec_best <-
  dec_fit_tree |>
  select_best(metric="mae")

dec_best
```

### Ostateczny model i jego dopasowanie
```{r}
dec_best_mod <-
  dec_workflow |>
  finalize_workflow(dec_best)

dec_final_fit <-
  dec_best_mod |>
  last_fit(split = data_split)
```

## Wizualizacja

### Wykres dla linear regression
```{r}
lin_fit |> 
  extract_fit_parsnip() |> 
  vip(num_features = 20) +
  scale_x_discrete(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  geom_boxplot(color = "black", fill = "grey85") +
  ggdark::dark_theme_dark()
```



### Wykres dla rand forest
```{r}
rf_fit |> 
  extract_fit_parsnip() |> 
  vip(num_features = 20) +
  scale_x_discrete(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  geom_boxplot(color = "black", fill = "grey85") +
  ggdark::dark_theme_dark()

```

### Wykres dla decision tree
```{r}

dec_final_fit |> 
extract_fit_parsnip() |> 
  vip(num_features = 20) +
  scale_x_discrete(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  geom_boxplot(color = "black", fill = "grey85") +
  ggdark::dark_theme_dark()
```

### Wykresu rozrzutu z linią idealną

```{r}
plot_scatter_with_ideal <- function(final_fit, model_name) {
  final_fit |> 
    collect_predictions() |> 
    ggplot(aes(x = .pred, y = o3)) +
    geom_point(alpha = 0.5, color = "blue") +
    geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
    labs(title = paste("Scatter plot with ideal line for", model_name),
         x = "Predicted O3 Levels",
         y = "Actual O3 Levels") +
    theme_minimal()
}
```

```{r}
# Wykresy dla poszczególnych modeli
plot_scatter_with_ideal(lin_fit, "Linear Regression (GLMNet)")
plot_scatter_with_ideal(rf_fit, "Random Forest (Ranger)")
plot_scatter_with_ideal(dec_final_fit, "Decision Tree (RPart)")
```

## Metryki

### Zebranie metryk
```{r}
lin_metrics <- lin_fit |> collect_metrics()
rf_metrics <- rf_fit |> collect_metrics()
dec_metrics <- dec_final_fit |> collect_metrics()
```


### Połączenie metryk
```{r}
all_metrics <- bind_rows(
  lin_metrics |> mutate(Model = "Linear Regression (GLMNet)"),
  rf_metrics |> mutate(Model = "Random Forest (Ranger)"),
  dec_metrics |> mutate(Model = "Decision Tree (RPart)")
)
```

### Posortowanie wyników według rmse

```{r}
all_metrics |> 
  filter(.metric == "rmse") |> 
  group_by(Model) |> 
  summarize(mean_rmse = mean(.estimate)) |> 
  arrange(mean_rmse)
all_metrics
```

Model najlepszy to taki, który posiada najmniejszą wartość RMSE(błąd średniokwadratowy), a więc jest to model Lasu losowego RMSE = 3.03.

